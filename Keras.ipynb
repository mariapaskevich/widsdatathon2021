{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dictionary = pd.read_csv(\"DataDictionaryWiDS2021.csv\")\n",
    "unlabeled = pd.read_csv(\"UnlabeledWiDS2021.csv\")\n",
    "training = pd.read_csv(\"TrainingWiDS2021.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_datatype_mapping = dict(zip(data_dictionary['Variable Name'], data_dictionary['Data Type']))\n",
    "\n",
    "del training['Unnamed: 0']\n",
    "del unlabeled['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140391, 177)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = training.append(unlabeled).drop(['encounter_id', \n",
    "                                            'hospital_id', \n",
    "                                            'diabetes_mellitus'], axis=1)\n",
    "\n",
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['ethnicity', 'gender', 'hospital_admit_source',\n",
    "           'icu_admit_source', 'icu_stay_type', 'icu_type',\n",
    "           'apache_2_diagnosis', 'apache_3j_diagnosis','icu_id']\n",
    "\n",
    "\n",
    "all_data = pd.get_dummies(all_data,dummy_na=True,columns=cat_cols)\n",
    "\n",
    "'''\n",
    "binary_cols = data_dictionary.loc[data_dictionary['Data Type'] == 'binary','Variable Name'].values\n",
    "num_cols = data_dictionary.loc[data_dictionary['Data Type'] == 'numeric','Variable Name'].values \n",
    "\n",
    "for col in all_data.columns:\n",
    "    if col in cat_cols:\n",
    "        #print(col)\n",
    "        all_data[col] = LabelEncoder().fit_transform(all_data[col].astype('str'))\n",
    "        all_data[col]= all_data[col].astype('category')     '''\n",
    "        \n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(all_data.values)\n",
    "all_data = pd.DataFrame(x_scaled)\n",
    "all_data = all_data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = all_data[:len(training)]\n",
    "df_pred = all_data[len(training):].reset_index(drop=True)\n",
    "Y = training['diabetes_mellitus']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(df_train, Y, test_size=0.20, random_state=42,shuffle=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop_callback = EarlyStopping(\n",
    "  monitor='val_accuracy', min_delta=0.0001,\n",
    "  patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3nthdkh5) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 8605<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 3.53MB of 3.53MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/jupyter/wids/wandb/run-20210224_194229-3nthdkh5/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/jupyter/wids/wandb/run-20210224_194229-3nthdkh5/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>49</td></tr><tr><td>loss</td><td>0.18155</td></tr><tr><td>accuracy</td><td>0.93413</td></tr><tr><td>val_loss</td><td>0.13171</td></tr><tr><td>val_accuracy</td><td>0.95974</td></tr><tr><td>_step</td><td>49</td></tr><tr><td>_runtime</td><td>2265</td></tr><tr><td>_timestamp</td><td>1614198014</td></tr><tr><td>best_val_loss</td><td>0.13138</td></tr><tr><td>best_epoch</td><td>48</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>accuracy</td><td>▁▂▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇████████</td></tr><tr><td>val_loss</td><td>█▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇████████</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▁▁▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▆▆▆▆▇▇██</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▁▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▆▆▆▆▇▇██</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">generous-voice-133</strong>: <a href=\"https://wandb.ai/mariapaskevich/wids_2021/runs/3nthdkh5\" target=\"_blank\">https://wandb.ai/mariapaskevich/wids_2021/runs/3nthdkh5</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:3nthdkh5). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.20 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.13<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">dark-star-134</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mariapaskevich/wids_2021\" target=\"_blank\">https://wandb.ai/mariapaskevich/wids_2021</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/mariapaskevich/wids_2021/runs/2eda1l08\" target=\"_blank\">https://wandb.ai/mariapaskevich/wids_2021/runs/2eda1l08</a><br/>\n",
       "                Run data is saved locally in <code>/home/jupyter/wids/wandb/run-20210224_211337-2eda1l08</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/29\n",
      "261/261 [==============================] - 12s 48ms/step - loss: 0.5718 - accuracy: 0.7753 - val_loss: 0.4959 - val_accuracy: 0.7832\n",
      "Epoch 2/29\n",
      "261/261 [==============================] - 12s 45ms/step - loss: 0.4762 - accuracy: 0.7955 - val_loss: 0.4473 - val_accuracy: 0.8185\n",
      "Epoch 3/29\n",
      "261/261 [==============================] - 12s 46ms/step - loss: 0.4449 - accuracy: 0.8198 - val_loss: 0.4264 - val_accuracy: 0.8280\n",
      "Epoch 4/29\n",
      "261/261 [==============================] - 11s 44ms/step - loss: 0.4301 - accuracy: 0.8265 - val_loss: 0.4149 - val_accuracy: 0.8322\n",
      "Epoch 5/29\n",
      "261/261 [==============================] - 10s 39ms/step - loss: 0.4210 - accuracy: 0.8291 - val_loss: 0.4052 - val_accuracy: 0.8364\n",
      "Epoch 6/29\n",
      "261/261 [==============================] - 11s 42ms/step - loss: 0.4112 - accuracy: 0.8333 - val_loss: 0.3962 - val_accuracy: 0.8395\n",
      "Epoch 7/29\n",
      "261/261 [==============================] - 12s 44ms/step - loss: 0.4040 - accuracy: 0.8353 - val_loss: 0.3885 - val_accuracy: 0.8425\n",
      "Epoch 8/29\n",
      "261/261 [==============================] - 10s 39ms/step - loss: 0.3958 - accuracy: 0.8384 - val_loss: 0.3796 - val_accuracy: 0.8475\n",
      "Epoch 9/29\n",
      "261/261 [==============================] - 11s 41ms/step - loss: 0.3881 - accuracy: 0.8418 - val_loss: 0.3715 - val_accuracy: 0.8491\n",
      "Epoch 10/29\n",
      "261/261 [==============================] - 11s 43ms/step - loss: 0.3809 - accuracy: 0.8445 - val_loss: 0.3624 - val_accuracy: 0.8573\n",
      "Epoch 11/29\n",
      "261/261 [==============================] - 11s 41ms/step - loss: 0.3729 - accuracy: 0.8486 - val_loss: 0.3527 - val_accuracy: 0.8607\n",
      "Epoch 12/29\n",
      "261/261 [==============================] - 12s 45ms/step - loss: 0.3652 - accuracy: 0.8513 - val_loss: 0.3446 - val_accuracy: 0.8622\n",
      "Epoch 13/29\n",
      "261/261 [==============================] - 12s 47ms/step - loss: 0.3572 - accuracy: 0.8554 - val_loss: 0.3339 - val_accuracy: 0.8703\n",
      "Epoch 14/29\n",
      "261/261 [==============================] - 12s 48ms/step - loss: 0.3495 - accuracy: 0.8588 - val_loss: 0.3266 - val_accuracy: 0.8722\n",
      "Epoch 15/29\n",
      "261/261 [==============================] - 11s 42ms/step - loss: 0.3426 - accuracy: 0.8616 - val_loss: 0.3154 - val_accuracy: 0.8801\n",
      "Epoch 16/29\n",
      "261/261 [==============================] - 11s 42ms/step - loss: 0.3342 - accuracy: 0.8664 - val_loss: 0.3060 - val_accuracy: 0.8843\n",
      "Epoch 17/29\n",
      "261/261 [==============================] - 12s 48ms/step - loss: 0.3277 - accuracy: 0.8693 - val_loss: 0.2979 - val_accuracy: 0.8861\n",
      "Epoch 18/29\n",
      "261/261 [==============================] - 12s 45ms/step - loss: 0.3202 - accuracy: 0.8723 - val_loss: 0.2908 - val_accuracy: 0.8896\n",
      "Epoch 19/29\n",
      "261/261 [==============================] - 14s 55ms/step - loss: 0.3116 - accuracy: 0.8774 - val_loss: 0.2804 - val_accuracy: 0.8965\n",
      "Epoch 20/29\n",
      "261/261 [==============================] - 12s 48ms/step - loss: 0.3061 - accuracy: 0.8795 - val_loss: 0.2731 - val_accuracy: 0.9000\n",
      "Epoch 21/29\n",
      "261/261 [==============================] - 12s 47ms/step - loss: 0.2989 - accuracy: 0.8827 - val_loss: 0.2649 - val_accuracy: 0.9030\n",
      "Epoch 22/29\n",
      "261/261 [==============================] - 11s 41ms/step - loss: 0.2924 - accuracy: 0.8862 - val_loss: 0.2567 - val_accuracy: 0.9098\n",
      "Epoch 23/29\n",
      "261/261 [==============================] - 11s 42ms/step - loss: 0.2862 - accuracy: 0.8881 - val_loss: 0.2492 - val_accuracy: 0.9121\n",
      "Epoch 24/29\n",
      "261/261 [==============================] - 11s 43ms/step - loss: 0.2798 - accuracy: 0.8915 - val_loss: 0.2431 - val_accuracy: 0.9138\n",
      "Epoch 25/29\n",
      "261/261 [==============================] - 10s 40ms/step - loss: 0.2743 - accuracy: 0.8949 - val_loss: 0.2342 - val_accuracy: 0.9202\n",
      "Epoch 26/29\n",
      "261/261 [==============================] - 11s 43ms/step - loss: 0.2699 - accuracy: 0.8959 - val_loss: 0.2296 - val_accuracy: 0.9213\n",
      "Epoch 27/29\n",
      "261/261 [==============================] - 12s 46ms/step - loss: 0.2635 - accuracy: 0.8991 - val_loss: 0.2218 - val_accuracy: 0.9252\n",
      "Epoch 28/29\n",
      "261/261 [==============================] - 14s 53ms/step - loss: 0.2583 - accuracy: 0.9020 - val_loss: 0.2167 - val_accuracy: 0.9269\n",
      "Epoch 29/29\n",
      "261/261 [==============================] - 14s 54ms/step - loss: 0.2528 - accuracy: 0.9035 - val_loss: 0.2108 - val_accuracy: 0.9324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9650286957823331"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"wids_2021\", sync_tensorboard=True)\n",
    "config = wandb.config\n",
    "config.learning_rate = 0.0001\n",
    "config.batch_size = 500\n",
    "config.activation = 'relu'\n",
    "config.optimizer = 'adam'\n",
    "config.epochs = 29\n",
    "\n",
    "tf.random.set_seed(87)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(1028,)),\n",
    "    keras.layers.Dense(256, activation=tf.nn.relu,activity_regularizer=tf.keras.regularizers.L2(0.01)),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu,activity_regularizer=tf.keras.regularizers.L2(0.01)),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    keras.layers.Dense(64, activation=tf.nn.relu,activity_regularizer=tf.keras.regularizers.L2(0.01)),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    #keras.layers.Dense(64, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(1, activation=tf.nn.sigmoid),\n",
    "])\n",
    "\n",
    "earlystop_callback = EarlyStopping(\n",
    "  monitor='val_accuracy', min_delta=0.0001,\n",
    "  patience=50)\n",
    "\n",
    "'''lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=.0001,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.9)\n",
    "opt = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "'''\n",
    "step = tf.Variable(0, trainable=False)\n",
    "boundaries = [30, 60]\n",
    "values = [0.0001, .00001, 0.000001]\n",
    "learning_rate_fn = keras.optimizers.schedules.PiecewiseConstantDecay(\n",
    "    boundaries, values)\n",
    "learning_rate = learning_rate_fn(step)\n",
    "opt = keras.optimizers.Nadam(learning_rate=learning_rate)\n",
    "\n",
    "#opt = keras.optimizers.Adam(learning_rate=config.learning_rate)\n",
    "\n",
    "model.compile(optimizer=opt,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(df_train, Y,\n",
    "         epochs=config.epochs,\n",
    "         batch_size=config.batch_size,\n",
    "         validation_data=(X_val, y_val),\n",
    "         #validation_freq=1,\n",
    "         callbacks=[earlystop_callback, WandbCallback(validation_data=(X_val, y_val))])\n",
    "\n",
    "#model.fit(X_train, y_train, \n",
    "#          epochs=config.epochs, \n",
    "#          batch_size=config.batch_size,\n",
    "#          callbacks=[earlystop_callback, WandbCallback(validation_data=(X_val, y_val))])\n",
    "\n",
    "metrics.roc_auc_score(y_val, model.predict(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(X_train, y_train, epochs=50, batch_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9863086316807583"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(y_val, model.predict(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_for_ensemble = pd.DataFrame(zip(Y.values,model.predict(df_train).reshape(-1)), columns=['diabetes_mellitus','pred'])\n",
    "train_for_ensemble.to_csv('ensemble/TRAIN_Keras_29_epochs.csv')\n",
    "\n",
    "submittion = pd.DataFrame([unlabeled.encounter_id,model.predict(df_pred).reshape(-1)]).T\n",
    "submittion.encounter_id = submittion.encounter_id.astype('int32')\n",
    "submittion.set_index('encounter_id',inplace=True)\n",
    "submittion.columns = ['diabetes_mellitus']\n",
    "submittion.to_csv('ensemble/SOLUTION_Keras_29_epochs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submittion = pd.DataFrame([unlabeled.encounter_id,model.predict(df_pred).reshape(-1)]).T\n",
    "submittion.encounter_id = submittion.encounter_id.astype('int32')\n",
    "submittion.set_index('encounter_id',inplace=True)\n",
    "submittion.columns = ['diabetes_mellitus']\n",
    "submittion.fillna(0.5).to_csv('submissions/SolutionWiDS2021_Keras_29_epochs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m61",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m61"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
