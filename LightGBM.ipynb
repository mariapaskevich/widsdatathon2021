{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn import metrics\n",
    "import lightgbm as lgb\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 181)\n",
    "pd.set_option(\"display.min_rows\", 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dictionary = pd.read_csv(\"DataDictionaryWiDS2021.csv\",index_col=0)\n",
    "unlabeled = pd.read_csv(\"UnlabeledWiDS2021.csv\",index_col=0)\n",
    "training = pd.read_csv(\"TrainingWiDS2021.csv\",index_col=0)\n",
    "\n",
    "column_datatype_mapping = dict(zip(data_dictionary['Variable Name'], data_dictionary['Data Type']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = training.drop(['encounter_id', \n",
    "                          'hospital_id', \n",
    "                          'diabetes_mellitus'], axis=1).append(unlabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = []\n",
    "cont_cols = []\n",
    "for col in all_data.columns:\n",
    "    if all_data.dtypes[col] == \"object\":\n",
    "        cat_cols.append(col)\n",
    "        all_data[col] = all_data[col].fillna(\"NA\")\n",
    "        all_data[col] = LabelEncoder().fit_transform(all_data[col])\n",
    "        all_data[col]= all_data[col].astype('category')\n",
    "    elif column_datatype_mapping[col] == \"binary\":\n",
    "        all_data[col] = all_data[col].fillna(-1)\n",
    "    elif column_datatype_mapping[col] == \"numeric\":\n",
    "        all_data[col] = all_data[col].fillna(0)\n",
    "        cont_cols.append(col)\n",
    "    else:\n",
    "        all_data[col] = all_data[col].fillna(all_data[col].median())\n",
    "        cont_cols.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = all_data[:len(training)][0:120000]\n",
    "y = training['diabetes_mellitus'][0:120000]\n",
    "\n",
    "X_holdout = all_data[:len(training)][120000:]\n",
    "y_holdout =  training['diabetes_mellitus'][120000:]\n",
    "\n",
    "X_all = all_data[:len(training)]\n",
    "y_all = training['diabetes_mellitus']\n",
    "X_pred = all_data[len(training):].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                      test_size=0.20, random_state=42,shuffle=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2h8wrkac) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 10223<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/jupyter/wids/wandb/run-20210116_192241-2h8wrkac/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/jupyter/wids/wandb/run-20210116_192241-2h8wrkac/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>val_auc</td><td>0.86796</td></tr><tr><td>_step</td><td>310</td></tr><tr><td>_runtime</td><td>20</td></tr><tr><td>_timestamp</td><td>1610824985</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>val_auc</td><td>▁▂▃▃▄▄▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇███████████████████</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▂▂▂▂▂▂▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█</td></tr><tr><td>_timestamp</td><td>▁▁▂▂▂▂▂▂▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">scarlet-paper-13</strong>: <a href=\"https://wandb.ai/mariapaskevich/wids_2021/runs/2h8wrkac\" target=\"_blank\">https://wandb.ai/mariapaskevich/wids_2021/runs/2h8wrkac</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:2h8wrkac). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.14 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.13<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">usual-shadow-14</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mariapaskevich/wids_2021\" target=\"_blank\">https://wandb.ai/mariapaskevich/wids_2021</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/mariapaskevich/wids_2021/runs/qrw2s7tu\" target=\"_blank\">https://wandb.ai/mariapaskevich/wids_2021/runs/qrw2s7tu</a><br/>\n",
       "                Run data is saved locally in <code>/home/jupyter/wids/wandb/run-20210116_192957-qrw2s7tu</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "from wandb.lightgbm import wandb_callback\n",
    "\n",
    "wandb.init(project=\"wids_2021\", sync_tensorboard=True)\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'learning_rate':0.05,\n",
    "          'num_leaves':30,\n",
    "          'n_estimators':2000,\n",
    "          'metric': 'auc',\n",
    "          'objective': 'binary',\n",
    "          'scale_pos_weight': 2}\n",
    "\n",
    "watchlist = [(X_train, 'train'), (X_test, 'test')]\n",
    "num_round = 5\n",
    "\n",
    "# create dataset for lightgbm\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:151: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 20755, number of negative: 75245\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.049201 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 25346\n",
      "[LightGBM] [Info] Number of data points in the train set: 96000, number of used features: 176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/opt/conda/lib/python3.7/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.216198 -> initscore=-1.287962\n",
      "[LightGBM] [Info] Start training from score -1.287962\n",
      "[1]\tval's auc: 0.80543\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[2]\tval's auc: 0.810281\n",
      "[3]\tval's auc: 0.8163\n",
      "[4]\tval's auc: 0.817855\n",
      "[5]\tval's auc: 0.819504\n",
      "[6]\tval's auc: 0.821013\n",
      "[7]\tval's auc: 0.822553\n",
      "[8]\tval's auc: 0.823887\n",
      "[9]\tval's auc: 0.824975\n",
      "[10]\tval's auc: 0.825797\n",
      "[11]\tval's auc: 0.826827\n",
      "[12]\tval's auc: 0.827457\n",
      "[13]\tval's auc: 0.827934\n",
      "[14]\tval's auc: 0.828601\n",
      "[15]\tval's auc: 0.829\n",
      "[16]\tval's auc: 0.829645\n",
      "[17]\tval's auc: 0.830169\n",
      "[18]\tval's auc: 0.830595\n",
      "[19]\tval's auc: 0.831164\n",
      "[20]\tval's auc: 0.831771\n",
      "[21]\tval's auc: 0.832588\n",
      "[22]\tval's auc: 0.833339\n",
      "[23]\tval's auc: 0.833997\n",
      "[24]\tval's auc: 0.834489\n",
      "[25]\tval's auc: 0.834955\n",
      "[26]\tval's auc: 0.835285\n",
      "[27]\tval's auc: 0.835653\n",
      "[28]\tval's auc: 0.83634\n",
      "[29]\tval's auc: 0.836849\n",
      "[30]\tval's auc: 0.83722\n",
      "[31]\tval's auc: 0.837564\n",
      "[32]\tval's auc: 0.83795\n",
      "[33]\tval's auc: 0.838382\n",
      "[34]\tval's auc: 0.838812\n",
      "[35]\tval's auc: 0.839251\n",
      "[36]\tval's auc: 0.839631\n",
      "[37]\tval's auc: 0.840034\n",
      "[38]\tval's auc: 0.840423\n",
      "[39]\tval's auc: 0.841043\n",
      "[40]\tval's auc: 0.841365\n",
      "[41]\tval's auc: 0.841931\n",
      "[42]\tval's auc: 0.842424\n",
      "[43]\tval's auc: 0.842974\n",
      "[44]\tval's auc: 0.843245\n",
      "[45]\tval's auc: 0.843592\n",
      "[46]\tval's auc: 0.843863\n",
      "[47]\tval's auc: 0.844144\n",
      "[48]\tval's auc: 0.844512\n",
      "[49]\tval's auc: 0.844773\n",
      "[50]\tval's auc: 0.845067\n",
      "[51]\tval's auc: 0.84541\n",
      "[52]\tval's auc: 0.845859\n",
      "[53]\tval's auc: 0.84631\n",
      "[54]\tval's auc: 0.846506\n",
      "[55]\tval's auc: 0.846813\n",
      "[56]\tval's auc: 0.84723\n",
      "[57]\tval's auc: 0.847718\n",
      "[58]\tval's auc: 0.848398\n",
      "[59]\tval's auc: 0.848661\n",
      "[60]\tval's auc: 0.848858\n",
      "[61]\tval's auc: 0.849453\n",
      "[62]\tval's auc: 0.849879\n",
      "[63]\tval's auc: 0.850093\n",
      "[64]\tval's auc: 0.850476\n",
      "[65]\tval's auc: 0.850763\n",
      "[66]\tval's auc: 0.851304\n",
      "[67]\tval's auc: 0.851564\n",
      "[68]\tval's auc: 0.851811\n",
      "[69]\tval's auc: 0.852133\n",
      "[70]\tval's auc: 0.852352\n",
      "[71]\tval's auc: 0.852591\n",
      "[72]\tval's auc: 0.852751\n",
      "[73]\tval's auc: 0.852939\n",
      "[74]\tval's auc: 0.853111\n",
      "[75]\tval's auc: 0.853325\n",
      "[76]\tval's auc: 0.853758\n",
      "[77]\tval's auc: 0.853909\n",
      "[78]\tval's auc: 0.854047\n",
      "[79]\tval's auc: 0.854203\n",
      "[80]\tval's auc: 0.854388\n",
      "[81]\tval's auc: 0.854569\n",
      "[82]\tval's auc: 0.854998\n",
      "[83]\tval's auc: 0.855118\n",
      "[84]\tval's auc: 0.855338\n",
      "[85]\tval's auc: 0.85562\n",
      "[86]\tval's auc: 0.855789\n",
      "[87]\tval's auc: 0.855986\n",
      "[88]\tval's auc: 0.856115\n",
      "[89]\tval's auc: 0.856256\n",
      "[90]\tval's auc: 0.856427\n",
      "[91]\tval's auc: 0.85668\n",
      "[92]\tval's auc: 0.856883\n",
      "[93]\tval's auc: 0.857309\n",
      "[94]\tval's auc: 0.857402\n",
      "[95]\tval's auc: 0.857539\n",
      "[96]\tval's auc: 0.857723\n",
      "[97]\tval's auc: 0.857834\n",
      "[98]\tval's auc: 0.857988\n",
      "[99]\tval's auc: 0.858037\n",
      "[100]\tval's auc: 0.8583\n",
      "[101]\tval's auc: 0.858445\n",
      "[102]\tval's auc: 0.858559\n",
      "[103]\tval's auc: 0.858721\n",
      "[104]\tval's auc: 0.858875\n",
      "[105]\tval's auc: 0.859001\n",
      "[106]\tval's auc: 0.859138\n",
      "[107]\tval's auc: 0.859268\n",
      "[108]\tval's auc: 0.859389\n",
      "[109]\tval's auc: 0.859496\n",
      "[110]\tval's auc: 0.859713\n",
      "[111]\tval's auc: 0.859774\n",
      "[112]\tval's auc: 0.859853\n",
      "[113]\tval's auc: 0.859976\n",
      "[114]\tval's auc: 0.860116\n",
      "[115]\tval's auc: 0.86043\n",
      "[116]\tval's auc: 0.860598\n",
      "[117]\tval's auc: 0.860695\n",
      "[118]\tval's auc: 0.860755\n",
      "[119]\tval's auc: 0.860856\n",
      "[120]\tval's auc: 0.860913\n",
      "[121]\tval's auc: 0.861009\n",
      "[122]\tval's auc: 0.86113\n",
      "[123]\tval's auc: 0.861239\n",
      "[124]\tval's auc: 0.86128\n",
      "[125]\tval's auc: 0.861354\n",
      "[126]\tval's auc: 0.861482\n",
      "[127]\tval's auc: 0.861746\n",
      "[128]\tval's auc: 0.86186\n",
      "[129]\tval's auc: 0.861983\n",
      "[130]\tval's auc: 0.862014\n",
      "[131]\tval's auc: 0.862117\n",
      "[132]\tval's auc: 0.862168\n",
      "[133]\tval's auc: 0.862199\n",
      "[134]\tval's auc: 0.862313\n",
      "[135]\tval's auc: 0.862382\n",
      "[136]\tval's auc: 0.862479\n",
      "[137]\tval's auc: 0.862561\n",
      "[138]\tval's auc: 0.862629\n",
      "[139]\tval's auc: 0.862723\n",
      "[140]\tval's auc: 0.862778\n",
      "[141]\tval's auc: 0.862841\n",
      "[142]\tval's auc: 0.862952\n",
      "[143]\tval's auc: 0.863027\n",
      "[144]\tval's auc: 0.863096\n",
      "[145]\tval's auc: 0.863193\n",
      "[146]\tval's auc: 0.863456\n",
      "[147]\tval's auc: 0.863536\n",
      "[148]\tval's auc: 0.863559\n",
      "[149]\tval's auc: 0.863642\n",
      "[150]\tval's auc: 0.863694\n",
      "[151]\tval's auc: 0.863776\n",
      "[152]\tval's auc: 0.86393\n",
      "[153]\tval's auc: 0.863949\n",
      "[154]\tval's auc: 0.864058\n",
      "[155]\tval's auc: 0.864107\n",
      "[156]\tval's auc: 0.864257\n",
      "[157]\tval's auc: 0.864299\n",
      "[158]\tval's auc: 0.864346\n",
      "[159]\tval's auc: 0.864417\n",
      "[160]\tval's auc: 0.864477\n",
      "[161]\tval's auc: 0.864486\n",
      "[162]\tval's auc: 0.864567\n",
      "[163]\tval's auc: 0.86463\n",
      "[164]\tval's auc: 0.864701\n",
      "[165]\tval's auc: 0.864736\n",
      "[166]\tval's auc: 0.864831\n",
      "[167]\tval's auc: 0.864861\n",
      "[168]\tval's auc: 0.86486\n",
      "[169]\tval's auc: 0.86487\n",
      "[170]\tval's auc: 0.864923\n",
      "[171]\tval's auc: 0.864995\n",
      "[172]\tval's auc: 0.865066\n",
      "[173]\tval's auc: 0.865067\n",
      "[174]\tval's auc: 0.865097\n",
      "[175]\tval's auc: 0.865138\n",
      "[176]\tval's auc: 0.865176\n",
      "[177]\tval's auc: 0.865208\n",
      "[178]\tval's auc: 0.86528\n",
      "[179]\tval's auc: 0.865304\n",
      "[180]\tval's auc: 0.865301\n",
      "[181]\tval's auc: 0.865357\n",
      "[182]\tval's auc: 0.865407\n",
      "[183]\tval's auc: 0.865413\n",
      "[184]\tval's auc: 0.865449\n",
      "[185]\tval's auc: 0.865522\n",
      "[186]\tval's auc: 0.865654\n",
      "[187]\tval's auc: 0.865682\n",
      "[188]\tval's auc: 0.865718\n",
      "[189]\tval's auc: 0.865765\n",
      "[190]\tval's auc: 0.865744\n",
      "[191]\tval's auc: 0.865729\n",
      "[192]\tval's auc: 0.86577\n",
      "[193]\tval's auc: 0.86582\n",
      "[194]\tval's auc: 0.865945\n",
      "[195]\tval's auc: 0.865924\n",
      "[196]\tval's auc: 0.865972\n",
      "[197]\tval's auc: 0.865977\n",
      "[198]\tval's auc: 0.866059\n",
      "[199]\tval's auc: 0.86609\n",
      "[200]\tval's auc: 0.866107\n",
      "[201]\tval's auc: 0.866119\n",
      "[202]\tval's auc: 0.866143\n",
      "[203]\tval's auc: 0.86615\n",
      "[204]\tval's auc: 0.866187\n",
      "[205]\tval's auc: 0.866227\n",
      "[206]\tval's auc: 0.866285\n",
      "[207]\tval's auc: 0.866327\n",
      "[208]\tval's auc: 0.866441\n",
      "[209]\tval's auc: 0.866447\n",
      "[210]\tval's auc: 0.866455\n",
      "[211]\tval's auc: 0.866465\n",
      "[212]\tval's auc: 0.866519\n",
      "[213]\tval's auc: 0.86656\n",
      "[214]\tval's auc: 0.866555\n",
      "[215]\tval's auc: 0.866617\n",
      "[216]\tval's auc: 0.86671\n",
      "[217]\tval's auc: 0.866734\n",
      "[218]\tval's auc: 0.866759\n",
      "[219]\tval's auc: 0.866758\n",
      "[220]\tval's auc: 0.866762\n",
      "[221]\tval's auc: 0.866792\n",
      "[222]\tval's auc: 0.866797\n",
      "[223]\tval's auc: 0.866791\n",
      "[224]\tval's auc: 0.866801\n",
      "[225]\tval's auc: 0.866865\n",
      "[226]\tval's auc: 0.866887\n",
      "[227]\tval's auc: 0.866895\n",
      "[228]\tval's auc: 0.866957\n",
      "[229]\tval's auc: 0.866961\n",
      "[230]\tval's auc: 0.867033\n",
      "[231]\tval's auc: 0.867135\n",
      "[232]\tval's auc: 0.867117\n",
      "[233]\tval's auc: 0.867119\n",
      "[234]\tval's auc: 0.867146\n",
      "[235]\tval's auc: 0.867189\n",
      "[236]\tval's auc: 0.867179\n",
      "[237]\tval's auc: 0.867218\n",
      "[238]\tval's auc: 0.867285\n",
      "[239]\tval's auc: 0.867276\n",
      "[240]\tval's auc: 0.867276\n",
      "[241]\tval's auc: 0.867301\n",
      "[242]\tval's auc: 0.867308\n",
      "[243]\tval's auc: 0.867328\n",
      "[244]\tval's auc: 0.867323\n",
      "[245]\tval's auc: 0.867344\n",
      "[246]\tval's auc: 0.867365\n",
      "[247]\tval's auc: 0.867377\n",
      "[248]\tval's auc: 0.867389\n",
      "[249]\tval's auc: 0.867409\n",
      "[250]\tval's auc: 0.867457\n",
      "[251]\tval's auc: 0.867441\n",
      "[252]\tval's auc: 0.86746\n",
      "[253]\tval's auc: 0.867519\n",
      "[254]\tval's auc: 0.867588\n",
      "[255]\tval's auc: 0.867584\n",
      "[256]\tval's auc: 0.867598\n",
      "[257]\tval's auc: 0.867604\n",
      "[258]\tval's auc: 0.867614\n",
      "[259]\tval's auc: 0.86762\n",
      "[260]\tval's auc: 0.867678\n",
      "[261]\tval's auc: 0.867683\n",
      "[262]\tval's auc: 0.867688\n",
      "[263]\tval's auc: 0.867715\n",
      "[264]\tval's auc: 0.867712\n",
      "[265]\tval's auc: 0.8677\n",
      "[266]\tval's auc: 0.867687\n",
      "[267]\tval's auc: 0.867673\n",
      "[268]\tval's auc: 0.867706\n",
      "[269]\tval's auc: 0.867694\n",
      "[270]\tval's auc: 0.867688\n",
      "[271]\tval's auc: 0.867679\n",
      "[272]\tval's auc: 0.867719\n",
      "[273]\tval's auc: 0.867701\n",
      "[274]\tval's auc: 0.867701\n",
      "[275]\tval's auc: 0.867695\n",
      "[276]\tval's auc: 0.867715\n",
      "[277]\tval's auc: 0.867735\n",
      "[278]\tval's auc: 0.867749\n",
      "[279]\tval's auc: 0.867787\n",
      "[280]\tval's auc: 0.867792\n",
      "[281]\tval's auc: 0.867775\n",
      "[282]\tval's auc: 0.867772\n",
      "[283]\tval's auc: 0.867794\n",
      "[284]\tval's auc: 0.867801\n",
      "[285]\tval's auc: 0.8678\n",
      "[286]\tval's auc: 0.867791\n",
      "[287]\tval's auc: 0.867798\n",
      "[288]\tval's auc: 0.867774\n",
      "[289]\tval's auc: 0.867787\n",
      "[290]\tval's auc: 0.867802\n",
      "[291]\tval's auc: 0.867811\n",
      "[292]\tval's auc: 0.867794\n",
      "[293]\tval's auc: 0.867796\n",
      "[294]\tval's auc: 0.867824\n",
      "[295]\tval's auc: 0.867823\n",
      "[296]\tval's auc: 0.867837\n",
      "[297]\tval's auc: 0.867877\n",
      "[298]\tval's auc: 0.867904\n",
      "[299]\tval's auc: 0.867932\n",
      "[300]\tval's auc: 0.86795\n",
      "[301]\tval's auc: 0.867967\n",
      "[302]\tval's auc: 0.867949\n",
      "[303]\tval's auc: 0.867935\n",
      "[304]\tval's auc: 0.86793\n",
      "[305]\tval's auc: 0.867942\n",
      "[306]\tval's auc: 0.867941\n",
      "[307]\tval's auc: 0.86795\n",
      "[308]\tval's auc: 0.867953\n",
      "[309]\tval's auc: 0.867953\n",
      "[310]\tval's auc: 0.867957\n",
      "[311]\tval's auc: 0.867959\n",
      "Early stopping, best iteration is:\n",
      "[301]\tval's auc: 0.867967\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "\n",
    "wandb.config.update(params)\n",
    "\n",
    "# add lightgbm callback\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=20,\n",
    "                valid_sets=lgb_eval,\n",
    "                valid_names=('val'),\n",
    "                callbacks=[wandb_callback()],\n",
    "                early_stopping_rounds=10)\n",
    "\n",
    "# predict\n",
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "# eval\n",
    "#print('The rmse of prediction is:', mean_squared_error(y_test, y_pred) ** 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8679669913339565\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print(roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8620574119227021\n"
     ]
    }
   ],
   "source": [
    "y_pred_holdout = gbm.predict(X_holdout, num_iteration=gbm.best_iteration)\n",
    "\n",
    "print(roc_auc_score(y_holdout, y_pred_holdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test:  0.8422083333333333\n",
      "holdout:  0.8271143054051393\n"
     ]
    }
   ],
   "source": [
    "lgbmc = LGBMClassifier(n_estimators=500,learning_rate=0.05)\n",
    "lgbmc.fit(X_train, y_train)\n",
    "\n",
    "print('test: ',lgbmc.score(X_test, y_test))\n",
    "print('holdout: ',lgbmc.score(X_holdout, y_holdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''default setting:\n",
    "    test:  0.840125\n",
    "    holdout:  0.8280988480850645\n",
    "    all train set: 0.8768157958832125\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.761173517800555"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbmc.fit(X_all, y_all)\n",
    "\n",
    "AUC_FINAL=metrics.roc_auc_score(y.values, lgbmc.predict(X))\n",
    "AUC_FINAL\n",
    "#lgbmc.predict_proba(X_pred)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "submittion = pd.DataFrame([unlabeled.encounter_id,lgbmc.predict_proba(X_pred)[:,1]]).T#.set_index('encounter_id')\n",
    "submittion.encounter_id = submittion.encounter_id.astype('int32')\n",
    "submittion.set_index('encounter_id',inplace=True)\n",
    "submittion.columns = ['diabetes_mellitus']\n",
    "submittion.fillna(0.5).to_csv('SolutionWiDS2021_LightGBM.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diabetes_mellitus</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encounter_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>136852</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              diabetes_mellitus\n",
       "encounter_id                   \n",
       "136852                      NaN"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submittion[submittion['diabetes_mellitus'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m61",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m61"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
